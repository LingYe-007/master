\newpage
\section{第六章\quad 总结与展望}
\label{chap:conclusion}
\setcounter{section}{6} \setcounter{subsection}{0}

\subsection{全文总结}
\label{sec:summary}
在联邦环境下做推荐时，原始用户数据不能离开本地，异构图神经网络又依赖多类型节点与关系，因此常面临三方面困难：客户端数据分布不一致（Non-IID）、新用户或长尾物品交互极少（冷启动），以及模型参数在端云之间的通信成本偏高。本文从「推荐效果」和「通信效率」两条线回应了上述问题。

在效果方面，本文提出了基于属性-结构双视图对比学习的联邦推荐框架 FedASCL。思路是把显式属性与隐式结构当作两个视图，通过最大化互信息把属性侧的语义迁移到稀疏的交互空间，从而缓解新用户特征缺失；同时用全局类别原型做语义对齐，减轻本地数据偏斜带来的语义漂移。第三章在 MovieLens-1M、Yelp 和 ACM 上的实验表明，FedASCL 在冷启动和 Non-IID 设置下均优于 FedProto、FedHGNN 等基线，尤其在数据最稀疏的 Yelp 上，相比次优模型在 HR@10 和 NDCG@10 上分别有约 2.88\% 和 3.36\% 的提升。在效率方面，针对异构图模型参数量大、通信压力高的问题，本文设计了语义感知的压缩策略：用注意力机制对元路径做结构剪枝、用残差补偿做数值量化，在通信量降至约 $20\times$ 压缩比时，第四章实验显示推荐精度仍与未压缩模型相当。此外，本文在第五章设计并实现了一个面向学术场景的联邦论文推荐系统，采用端云协同的分层架构（数据存储、算法引擎、业务服务与展示分离），把 FedASCL 与上述压缩策略集成进本地训练器、联邦协调器和安全聚合器，形成完整的训练与推荐流程；系统支持根据用户是否有足够交互历史在结构视图与属性视图之间切换，以应对冷启动。经功能与推荐效果测试，在保护隐私的前提下，本文工作在实际部署所需的精度、通信开销和可落地性之间取得了可验证的平衡。

\subsection{研究不足与未来展望}
\label{sec:outlook}
本文工作仍有若干局限，后续可从以下三方面改进与拓展。

\textbf{（1）兴趣随时间变化的问题。} 本文 FedASCL 目前使用的是某一时刻的“快照”图，没有专门建模用户兴趣随时间、随场景的变化。在第三章实验中，Yelp 等数据集上的用户偏好会随时间和上下文发生漂移。若在现有双视图与原型对齐的基础上，引入动态图或联邦持续学习，让模型既能跟上用户的最新兴趣，又不过度遗忘过去的有用信息，将更符合真实业务需求。

\textbf{（2）隐私保护的加强。} 本文的隐私保护主要依靠“只传梯度、不传原始数据”的联邦聚合方式，在极端攻击假设下，图结构仍有可能被反推。第五章系统虽集成了本地差分隐私模块，但元路径聚合或本地上传阶段仍可进一步与可信执行环境（TEE）等技术结合，降低图结构泄露的风险。

\textbf{（3）跨域与少样本场景。} 本文当前实验集中在“同一数据域、单一推荐任务”的设定下（见第三、四章）。若扩展到跨域场景（例如不同平台、特征不重叠、数据分布差异大），如何利用少量重叠用户或共享特征做知识迁移，在目标域数据很少时仍能做好推荐，是后续在 FedASCL 与压缩策略基础上值得继续探索的方向。
