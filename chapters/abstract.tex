% --- 摘要页设置开始（不另起页，避免首页空白） ---
\pagenumbering{Roman} % 设置页码为罗马数字 I, II, III
\setcounter{page}{1} % 重置页码为 I
\markboth{摘\quad 要}{摘\quad 要}
% 抑制首页可能出现的脚注标记等多余输出
\makeatletter
\let\@makefnmark\relax
\renewcommand\@makefntext[1]{\relax}
\makeatother

% --- 中文摘要（标题与正文同页，与致谢页标题高度一致：上留约 3cm 与版心一致） ---
\begin{center}
    \par\vspace{3.5cm}
    % "摘要"标题（三号黑体加粗，1.5倍行距）
    {\fontsize{15.75pt}{23.625pt}\selectfont\heiti\bfseries 摘\quad 要}
    \par\vspace{1cm}
\end{center}

\phantomsection
% 摘要正文
{\fontsize{12pt}{18pt}\selectfont \songti
推荐系统已从单纯的流量分发转向对用户深度兴趣的挖掘。异构信息网络（Heterogeneous Information Network）因为能够整合多种异构数据源，挖掘隐藏的语义信息，成为提升推荐精度的可行技术。同时，在《个人信息保护法》与GDPR的合规要求下，以及各大平台之间的“数据围墙”日益增高，传统的集中式大图训练模式满足不了跨域数据融合与隐私合规的要求。联邦学习（Federated Learning, FL）通过"数据不动模型动"的分布式训练方式，允许参与方在本地保留原始数据的同时，仅上传交互加密的模型参数，满足了隐私合规的要求。然而，由于联邦学习场景的特性，现有联邦异构图推荐研究仍面临冷启动、推荐效果变差、通信瓶颈与落地困难等问题。

基于此，本文做了以下工作。以跨视图语义融合与结构化模型压缩为切入点，提出属性-结构双视图对比学习机制解决联邦推荐中的冷启动问题，并将语义感知压缩策略应用于异构图模型，通过研究冷启动、非IID数据适配及端侧轻量化等问题，提出了高效、保护隐私、可落地的联邦异构图推荐框架，从算法与系统两方面给出了解决方案。本文在MovieLens-1M、Yelp和ACM三个公开数据集上进行了广泛的实验验证，与FedNCF、FedGNN、FedPerGNN、FedHGNN、FedProto等5个基线方法进行了对比，使用 HR@K 和 NDCG@K（分别为命中率 Hit Rate at K 与归一化折损累积增益 Normalized Discounted Cumulative Gain at K）作为评估指标，实验表明所提模型在 HR@10、NDCG@10 等指标上有所提升。本文的研究工作如下：

1) 为解决\textbf{冷启动}和\textbf{数据异质性}的问题，本文提出了\textbf{基于属性-结构双视图对比学习的联邦异构图推荐框架（Federated Attribute-Structure Contrastive Learning, FedASCL）}。框架利用\textbf{跨视图对比学习机制}在潜在空间对齐用户属性与图结构语义，利用属性特征重构缺失的拓扑信息以解决\textbf{零交互用户的冷启动难题}；并引入\textbf{全局语义原型对齐（Global Semantic Prototype Alignment）机制}，通过约束本地模型表征向全局一致的语义原型靠拢，纠正\textbf{客户端模型漂移（Client Drift）}。实验表明，在冷启动场景下 FedASCL 相比现有方法性能有所提升，在高度异构环境下亦有明显提升。

2) 为降低联邦异构图模型的通信开销，本文提出了\textbf{语义感知的模型参数压缩策略}。该策略设计了轻量级的\textbf{元路径选择器}，在本地训练阶段动态剔除对用户贡献度低的冗余通道，并结合\textbf{残差梯度量化技术}压缩传输数据。实验结果表明，在约20倍压缩倍数下，该策略在保持推荐精度的同时，将通信开销降低了约一个数量级（见第四章表\ref{tab:communication_cost}），缓解了联邦推荐系统的通信瓶颈问题。

3) 为解决联邦推荐系统落地困难的问题，本文构建了支持\textbf{异构设备协同}的\textbf{联邦论文推荐系统}。该系统采用\textbf{端云协同的异步聚合架构}以适配不同性能的终端设备，并集成了\textbf{本地差分隐私模块}，完成了联邦推荐系统的落地。
\par
}

\vspace{1em}
% 关键词：小四号黑体，顶格
\noindent % 取消首行缩进
{\fontsize{12pt}{18pt}\selectfont\heiti\bfseries 关键词}：{\fontsize{12pt}{18pt}\selectfont\songti 联邦学习，异构图推荐，对比学习，冷启动，模型轻量化，系统实现}

% 中文摘要写入目录（放在正文后，避免在摘要标题前产生多余符号）
\addcontentsline{toc}{chapter}{摘\quad 要}

% --- 英文摘要 (另起一页，标题与正文同页，标题上多留间距) ---
\newpage
\markboth{ABSTRACT}{ABSTRACT}
\begin{center}
    \par\vspace{2.5cm}
    % "ABSTRACT" 标题：三号Times New Roman加粗，居中，1.5倍行距
    {\fontsize{15.75pt}{23.625pt}\selectfont\bfseries ABSTRACT}
    \par\vspace{1cm}
\end{center}

% 添加到目录
\phantomsection
\addcontentsline{toc}{chapter}{ABSTRACT}

% 英文摘要正文 (已填充你的文档内容)
{\fontsize{12pt}{18pt}\selectfont
With the rapid development of the mobile Internet, recommendation systems have shifted from mere traffic distribution to deep interest mining of users. Heterogeneous Information Networks (HINs) have emerged as a practical technology to improve recommendation accuracy by integrating diverse heterogeneous data sources and excavating hidden semantic information. Meanwhile, under the compliance requirements of the Personal Information Protection Law and GDPR, as well as the increasing "data silos" between major platforms, the traditional centralized large-graph training paradigm can no longer meet the demands of cross-domain data fusion and privacy compliance. Federated Learning (FL), through a distributed training paradigm of "models move while data stays", allows participants to retain raw data locally and only upload interactively encrypted model parameters, thus satisfying privacy compliance requirements. However, due to the characteristics of the federated scenario, existing research on federated heterogeneous graph recommendation still faces the cold start problem, recommendation performance constrained by Non-Independent and Identically Distributed (Non-IID) data, and communication bottlenecks and deployment difficulties brought by high-dimensional heterogeneous models.

This paper addresses the above issues as follows. Taking cross-view semantic fusion and structured model compression as entry points, it proposes an attribute-structure dual-view contrastive learning mechanism to solve the cold start problem in federated recommendation, and applies a semantics-aware compression strategy to heterogeneous graph models. By investigating cold start, Non-IID data adaptation, and edge-side lightweighting, it proposes an efficient, privacy-preserving, and deployable federated heterogeneous graph recommendation framework, with solutions at both algorithm and system levels. Extensive experiments are conducted on three public datasets (MovieLens-1M, Yelp, and ACM), comparing with five baseline methods including FedNCF, FedGNN, FedPerGNN, FedHGNN, and FedProto, using HR@K and NDCG@K (Hit Rate at K and Normalized Discounted Cumulative Gain at K) as evaluation metrics, achieving noticeable improvements. 

Specifically, the research work of this paper is as follows:

1) To tackle the poor recommendation performance caused by cold start and Non-IID data, this paper proposes a federated heterogeneous graph recommendation framework based on Federated Attribute-Structure Contrastive Learning (FedASCL). The framework employs a cross-view contrastive learning mechanism to align user attribute and graph structure semantics in the latent space and reconstructs missing topological information using attribute features; it also introduces a \textbf{Global Semantic Prototype Alignment} mechanism to correct \textbf{Client Drift}. Experiments show that FedASCL achieves noticeable performance improvement in cold start scenarios and noticeable improvement in highly heterogeneous environments.

2) To address the problems of large parameter size and low communication efficiency in federated heterogeneous graph models, this paper proposes a semantics-aware model parameter compression strategy. This strategy designs a lightweight meta-path selector to dynamically eliminate redundant channels with low contribution to users during local training, and combines residual gradient quantization technology to compress transmitted data. Experimental results show that at approximately 20$\times$ compression ratio, the strategy maintains recommendation accuracy while reducing communication overhead by approximately one order of magnitude (see Chapter 4 Table \ref{tab:communication_cost}), alleviating the communication bottleneck in federated recommendation systems.

3) To solve the difficulty in deploying current federated recommendation systems, this paper constructs a federated recommendation system supporting heterogeneous device collaboration. The system adopts an edge-cloud collaborative asynchronous aggregation architecture to adapt to terminal devices with different performances, and integrates a local differential privacy module to complete the deployment of the federated recommendation system.
\par
}

\vspace{1em}
% 英文关键词
% KEYWORDS标题：小四号Times New Roman加粗，顶格
\noindent
\textbf{\fontsize{12pt}{18pt}\selectfont KEYWORDS}: \fontsize{12pt}{18pt}\selectfont Federated Learning; Heterogeneous Graph Recommendation; Contrastive Learning; Cold Start; Model Lightweighting; System Implementation
